{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzi\\AppData\\Local\\Temp\\ipykernel_15104\\266446362.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               step  type    amount     nameOrig  oldbalanceOrg  \\\n",
      "transactionId                                                     \n",
      "0                 1     3   9839.64  C1231006815       170136.0   \n",
      "1                 1     3   1864.28  C1666544295        21249.0   \n",
      "2                 1     4    181.00  C1305486145          181.0   \n",
      "3                 1     1    181.00   C840083671          181.0   \n",
      "4                 1     3  11668.14  C2048537720        41554.0   \n",
      "\n",
      "               newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  \\\n",
      "transactionId                                                                \n",
      "0                   160296.36  M1979787155             0.0             0.0   \n",
      "1                    19384.72  M2044282225             0.0             0.0   \n",
      "2                        0.00   C553264065             0.0             0.0   \n",
      "3                        0.00    C38997010         21182.0             0.0   \n",
      "4                    29885.86  M1230701703             0.0             0.0   \n",
      "\n",
      "               isFraud  \n",
      "transactionId           \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    1  \n",
      "3                    1  \n",
      "4                    0  \n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "data = pd.read_csv(r\"C:\\Users\\yzi\\OneDrive\\Bureau\\Travaux\\Projet2\\Projet_Classification_THBS\\database\\transactions.csv\", index_col=\"transactionId\")\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les lettres \"C\" et \"M\" par des chiffres dans les colonnes \"nameOrig\" et \"nameDest\"\n",
    "data[\"nameOrig\"] = data[\"nameOrig\"].apply(lambda x: 0 if x.startswith(\"C\") else 1)\n",
    "data[\"nameDest\"] = data[\"nameDest\"].apply(lambda x: 0 if x.startswith(\"M\") else 2)\n",
    "\n",
    "# Convertir une colonne en type 'category'\n",
    "data['isFraud'] = data['isFraud'].astype('category')\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les types et les valeurs numériques\n",
    "type_mapping = {'TRANSFER': 1, 'PAYMENT': 2, 'CASH_OUT': 3, 'CASH_IN': 4, 'DEBIT': 5}\n",
    "\n",
    "# Remplacer les valeurs de la colonne \"type\" par les valeurs numériques correspondantes\n",
    "data['type'] = data['type'].replace(type_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres trouvés:\n",
      "{'max_depth': 9, 'n_estimators': 300}\n",
      "Accuracy: 0.9996230962641897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    200061\n",
      "           1       0.97      0.98      0.98      1582\n",
      "\n",
      "    accuracy                           1.00    201643\n",
      "   macro avg       0.99      0.99      0.99    201643\n",
      "weighted avg       1.00      1.00      1.00    201643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Séparer les caractéristiques et la variable cible\n",
    "X = data.drop(\"isFraud\", axis=1)  # Utiliser \"isFraud\" au lieu de \"Class\"\n",
    "y = data[\"isFraud\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer l'objet SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=4)\n",
    "\n",
    "# Appliquer SMOTE sur les données d'entraînement uniquement\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Définir les hyperparamètres à rechercher\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [ 7, 9, 11]\n",
    "}\n",
    "\n",
    "# Instancier le modèle XGBClassifier\n",
    "model = XGBClassifier(enable_categorical=True)\n",
    "\n",
    "# Créer l'objet GridSearchCV avec SMOTE\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "# Effectuer la recherche sur la grille avec les données équilibrées\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Meilleurs hyperparamètres trouvés:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Obtenir les meilleures performances\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification report:\n",
      "{'0': {'precision': 0.9998719654999183, 'recall': 0.999587, 'f1-score': 0.9997294608163788, 'support': 1000000.0}, '1': {'precision': 0.9514585941330349, 'recall': 0.9844151841413502, 'f1-score': 0.9676346359964765, 'support': 8213.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Définir le nombre de plis pour la validation croisée\n",
    "n_splits = 10\n",
    "\n",
    "# Instancier la validation croisée stratifiée\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste pour stocker les rapports de classification de chaque pli\n",
    "cv_classification_reports = []\n",
    "\n",
    "# Boucle sur les plis de la validation croisée\n",
    "for train_idx, val_idx in stratified_kfold.split(X, y):\n",
    "    # Diviser les données en ensembles d'entraînement et de validation\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Appliquer SMOTE sur les données d'entraînement uniquement\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Entraîner le modèle sur l'ensemble d'entraînement\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Faire des prédictions sur l'ensemble de validation\n",
    "    y_pred_val = model.predict(X_val_fold)\n",
    "    \n",
    "    # Générer un rapport de classification pour ce pli\n",
    "    classification_report_fold = classification_report(y_val_fold, y_pred_val, output_dict=True)\n",
    "    \n",
    "    # Ajouter le rapport à la liste des rapports\n",
    "    cv_classification_reports.append(classification_report_fold)\n",
    "\n",
    "# Fusionner les rapports de tous les plis\n",
    "overall_classification_report = {\n",
    "    \"0\": {\"precision\": 0, \"recall\": 0, \"f1-score\": 0, \"support\": 0},\n",
    "    \"1\": {\"precision\": 0, \"recall\": 0, \"f1-score\": 0, \"support\": 0}\n",
    "}\n",
    "for report in cv_classification_reports:\n",
    "    for label in overall_classification_report.keys():\n",
    "        overall_classification_report[label][\"precision\"] += report[label][\"precision\"]\n",
    "        overall_classification_report[label][\"recall\"] += report[label][\"recall\"]\n",
    "        overall_classification_report[label][\"f1-score\"] += report[label][\"f1-score\"]\n",
    "        overall_classification_report[label][\"support\"] += report[label][\"support\"]\n",
    "\n",
    "# Calculer les moyennes des rapports de classification\n",
    "num_folds = len(cv_classification_reports)\n",
    "for label in overall_classification_report.keys():\n",
    "    overall_classification_report[label][\"precision\"] /= num_folds\n",
    "    overall_classification_report[label][\"recall\"] /= num_folds\n",
    "    overall_classification_report[label][\"f1-score\"] /= num_folds\n",
    "\n",
    "# Afficher le rapport de classification global\n",
    "print(\"Overall classification report:\")\n",
    "print(overall_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a été sauvegardé avec succès dans le fichier: XGBmodel.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Définir le nom du fichier pour sauvegarder le modèle\n",
    "filename = 'XGBmodel.pkl'\n",
    "\n",
    "# Utiliser pickle.dump() pour sauvegarder le modèle dans le fichier\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Le modèle a été sauvegardé avec succès dans le fichier:\", filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
